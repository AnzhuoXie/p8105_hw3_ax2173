---
title: "p8015_hw3_ax2173"
output: github_document
---

```{r}  
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = '90%'
)

theme_set(theme_classic() + theme(legend.position = 'bottom'))

options(
  ggplot2.continous.colour = 'viridis_d',
  ggplot2.continous.fill = 'viridis_d'
)

scalr_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1


## Problem 2

Import, clean and manipulate data.

```{r}
acc_df = 
  read_csv("./Data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_or_weekend = ifelse((day == 'Saturday' | day == "Sunday"), 'Weekend', 'Weekday')
    ) %>% 
  pivot_longer(
    activity_1 : activity_1440,
    names_to = 'activity_num',
    values_to = 'activity_counts'
  ) %>% 
  select(week, day_id, day, weekday_or_weekend, everything())
```

* There are some descriptions:
  * This dataset contains these variables: `r colnames(acc_df)`
  * There are totally `r nrow(acc_df)` observations
  * There are totally `r ncol(acc_df)` variables

Aggregate across minutes to create a total activity variable for each day, and create a table to show these totals. 

* As for any trends apparent, I am not sure, but I guess the day activity is relatively lower in weekends than in weekdays.

```{r}
acc_df %>% 
  group_by(week, day_id, day) %>% 
  summarize(day_activity = sum(activity_counts)) %>% 
  knitr::kable(digits = 2)
```

Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week.

```{r fig.width=6, fig.height=3}
acc_df %>% 
  group_by(week, day_id, day) %>% 
  summarize(day_activity = sum(activity_counts)) %>% 
  ggplot(aes(x = day_id, y = day_activity, color = week)) +
  geom_point() +
  geom_line() +
  labs(
    title = 'The daily activity of this 63-year-old man',
    x = 'the day ID',
    y = 'the day activity',
    caption = 'the day activity is aggregated across minutes'
  )
```

* About some patterns or conclusions I can make based on this graph.
  * A huge fluctuation can be found during the whole process
  * The highest data was in the Monday of week 3, reaching 685920.00
  * The lowest data appeared both in Saturday in week 4 and Saturday in week 5, with daily activity data of just 1440.00

## Problem 3

Download the needed data.

```{r}
library(p8105.datasets)
data("ny_noaa")
```

* There are some descriptions about the data:
  * The size of this dataset is `r nrow(ny_noaa)` x `r ncol(ny_noaa)`
  * This dataset had these variables: `r colnames(ny_noaa)`
  * Almost all the data in this dataset are missing, in other words, the extend of missing value is huge.
  
Next, do the data cleaning and create separate variables for year, month and day.
  
```{r}
ny_nozz = 
  ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, into = c('year', 'month',  'day'), sep = '-')
```

Calculate the most commonly observed values about snowfall. 
  * From the density plot, we can know that the most commonly observed values about snowfall is 0.

```{r fig.width=12, fig.height=9}
ny_noaa %>% 
  group_by(snow) %>% 
    summarize(snowfall_count = n()) %>% 
  ggplot(aes(x = snow)) +
  geom_density() +
    labs(
    title = 'The scatter plot of snowfall data',
    x = 'snowfall',
    y = 'snowfall_count',
    caption = 'Data from noaa package'
  )
```


  